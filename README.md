# __Machine Learning Algorithms__

## __Linear Regression__

Linear regression is a supervised learning algorithm and tries to model the relationship between a continuous target variable and one or more independent variables by fitting a linear equation to the data.
For a linear regression to be a good choice, there needs to be a linear relation between independent variable(s) and target variable. There are many tools to explore the relationship among variables such as scatter plots and correlation matrix. For example, the scatter plot below shows a positive correlation between an independent variable (x-axis) and dependent variable (y-axis). As one increases, the other one also increases.
<img src ='https://miro.medium.com/max/490/0*SJucFv9TduqDWgw7.png'>

A linear regression model tries to fit a regression line to the data points that best represents the relations or correlations. The most common technique to use is ordinary-least squares (OLE). With this method, best regression line is found by minimizing the sum of squares of the distance between data points and the regression line. For the data points above, the regression line obtained using OLE seems like:
<img src='https://miro.medium.com/max/508/0*e2N94sdwIpaNs5iE.jpeg'>

## __Logistic Regression__
## __Decision Tree__
## __Support Vector Machine(SVM)__
## __Naive Bayes__
## __K-Nearest Neighbors(kNN)__
## __k-Means Clustering__
## __Random Forest__
## __Dimensiopnality Reduction Algorithms(e.g. PCA)__
## __Gradient Boosting & AdaBoost(e,g. GBDT)__



